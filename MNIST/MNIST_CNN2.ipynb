{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, BatchNormalization, Flatten, Activation, MaxPooling2D, Dense\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_lv2(input_shape=(28,28,1,)):\n",
    "    x_input=Input(input_shape)\n",
    "    \n",
    "    x=Conv2D(6,(5,5), strides=(1,1), padding='valid', name='conv1', kernel_initializer=glorot_uniform(seed=0))(x_input)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv1')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    "    \n",
    "    x=Conv2D(32, (5,5), strides=(1,1), padding='valid', name='conv2', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv2')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    "    \n",
    "    x=Flatten()(x)\n",
    "    x=Dense(10, activation='softmax', name='fc', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    \n",
    "    model=Model(inputs=x_input, outputs=x, name='CNN_lv2')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_lv3(input_shape=(28,28,1,)):\n",
    "    x_input=Input(input_shape)\n",
    "    \n",
    "    x=Conv2D(6,(5,5), strides=(1,1), padding='valid', name='conv1', kernel_initializer=glorot_uniform(seed=0))(x_input)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv1')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    "    \n",
    "    x=Conv2D(32, (5,5), strides=(1,1), padding='valid', name='conv2', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv2')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    " \n",
    "    x=Conv2D(64, (5,5), strides=(1,1), padding='valid', name='conv3', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv3')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "    x=Dense(10, activation='softmax', name='fc', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    \n",
    "    model=Model(inputs=x_input, outputs=x, name='CNN_lv2')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_lv3_2(input_shape=(28,28,1,)):\n",
    "    x_input=Input(input_shape)\n",
    "    \n",
    "    x=Conv2D(12,(5,5), strides=(1,1), padding='valid', name='conv1', kernel_initializer=glorot_uniform(seed=0))(x_input)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv1')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    "    \n",
    "    x=Conv2D(32, (5,5), strides=(1,1), padding='valid', name='conv2', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv2')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    " \n",
    "    x=Conv2D(64, (5,5), strides=(1,1), padding='valid', name='conv3', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    x=BatchNormalization(axis=3, name='bn_conv3')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=MaxPooling2D((3,3), strides=(1,1))(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "    x=Dense(10, activation='softmax', name='fc', kernel_initializer=glorot_uniform(seed=0))(x)\n",
    "    \n",
    "    model=Model(inputs=x_input, outputs=x, name='CNN_lv2')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "y_train=train['label']\n",
    "x_train=train.drop(['label'], axis=1)\n",
    "\n",
    "x_train=np.array(x_train.values)\n",
    "x_train=np.array([i.reshape(28,28,1) for i in x_train])\n",
    "y_train=y_train.values #already numnp obj\n",
    "x_test=np.array(test.values)\n",
    "x_test=np.array([i.reshape(28,28,1) for i in x_test])\n",
    "                 \n",
    "y_train_mod=np.array([[0,0,0,0,0,0,0,0,0,0]])\n",
    "\n",
    "for i in y_train:\n",
    "    tmp=np.array([[0,0,0,0,0,0,0,0,0,0]])\n",
    "    tmp[0][i]=1\n",
    "    y_train_mod=np.append(y_train_mod, tmp, axis=0)\n",
    "\n",
    "y_train_mod=np.delete(y_train_mod, 0,0)\n",
    "\n",
    "y_train_mod\n",
    "\n",
    "x_val=x_train[40000:]\n",
    "y_val=y_train_mod[40000:]\n",
    "x_train=x_train[:40000]\n",
    "y_train=y_train_mod[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d24de1f98>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_lv2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 24, 24, 6)         24        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 22, 22, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 18, 18, 32)        4832      \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 87,070\n",
      "Trainable params: 86,994\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=CNN_lv2()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_lv2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 24, 24, 6)         24        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 24, 24, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 22, 22, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 18, 18, 32)        4832      \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 12, 12, 64)        51264     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 10)                64010     \n",
      "=================================================================\n",
      "Total params: 120,670\n",
      "Trainable params: 120,466\n",
      "Non-trainable params: 204\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2=CNN_lv3()\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_lv2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 24, 24, 12)        312       \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 24, 24, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 24, 24, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 22, 22, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 18, 18, 32)        9632      \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 12, 12, 64)        51264     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 10)                64010     \n",
      "=================================================================\n",
      "Total params: 125,650\n",
      "Trainable params: 125,434\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3=CNN_lv3_2()\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/15\n",
      "40000/40000 [==============================] - 25s 631us/sample - loss: 0.2175 - accuracy: 0.9419 - val_loss: 0.1107 - val_accuracy: 0.9725\n",
      "Epoch 2/15\n",
      "40000/40000 [==============================] - 25s 613us/sample - loss: 0.0908 - accuracy: 0.9755 - val_loss: 0.1305 - val_accuracy: 0.9670\n",
      "Epoch 3/15\n",
      "40000/40000 [==============================] - 24s 603us/sample - loss: 0.0686 - accuracy: 0.9812 - val_loss: 0.2062 - val_accuracy: 0.9425\n",
      "Epoch 4/15\n",
      "40000/40000 [==============================] - 24s 605us/sample - loss: 0.0536 - accuracy: 0.9846 - val_loss: 0.0784 - val_accuracy: 0.9775\n",
      "Epoch 5/15\n",
      "40000/40000 [==============================] - 24s 599us/sample - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.0991 - val_accuracy: 0.9750\n",
      "Epoch 6/15\n",
      "40000/40000 [==============================] - 24s 599us/sample - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0825 - val_accuracy: 0.9770\n",
      "Epoch 7/15\n",
      "40000/40000 [==============================] - 24s 599us/sample - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0470 - val_accuracy: 0.9885\n",
      "Epoch 8/15\n",
      "40000/40000 [==============================] - 24s 597us/sample - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.0875 - val_accuracy: 0.9785\n",
      "Epoch 9/15\n",
      "40000/40000 [==============================] - 24s 597us/sample - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0562 - val_accuracy: 0.9855\n",
      "Epoch 10/15\n",
      "40000/40000 [==============================] - 24s 599us/sample - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.0676 - val_accuracy: 0.9820\n",
      "Epoch 11/15\n",
      "40000/40000 [==============================] - 24s 595us/sample - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0399 - val_accuracy: 0.9890\n",
      "Epoch 12/15\n",
      "40000/40000 [==============================] - 24s 603us/sample - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0464 - val_accuracy: 0.9865\n",
      "Epoch 13/15\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0440 - val_accuracy: 0.9865\n",
      "Epoch 14/15\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0923 - val_accuracy: 0.9765\n",
      "Epoch 15/15\n",
      "40000/40000 [==============================] - 24s 598us/sample - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0682 - val_accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d25b62438>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/15\n",
      "40000/40000 [==============================] - 48s 1ms/sample - loss: 0.1755 - accuracy: 0.9495 - val_loss: 0.2502 - val_accuracy: 0.9375\n",
      "Epoch 2/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0878 - accuracy: 0.9756 - val_loss: 0.1028 - val_accuracy: 0.9730\n",
      "Epoch 3/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0630 - accuracy: 0.9826 - val_loss: 0.2026 - val_accuracy: 0.9460\n",
      "Epoch 4/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0497 - accuracy: 0.9866 - val_loss: 0.0933 - val_accuracy: 0.9760\n",
      "Epoch 5/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0466 - accuracy: 0.9875 - val_loss: 0.0944 - val_accuracy: 0.9735\n",
      "Epoch 6/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0398 - accuracy: 0.9882 - val_loss: 0.1009 - val_accuracy: 0.9795\n",
      "Epoch 7/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.0949 - val_accuracy: 0.9755\n",
      "Epoch 8/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.0399 - val_accuracy: 0.9895\n",
      "Epoch 9/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0626 - val_accuracy: 0.9830\n",
      "Epoch 10/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0225 - accuracy: 0.9934 - val_loss: 0.0686 - val_accuracy: 0.9845\n",
      "Epoch 11/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0484 - val_accuracy: 0.9865\n",
      "Epoch 12/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0657 - val_accuracy: 0.9845\n",
      "Epoch 13/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.1065 - val_accuracy: 0.9715\n",
      "Epoch 14/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0584 - val_accuracy: 0.9840\n",
      "Epoch 15/15\n",
      "40000/40000 [==============================] - 46s 1ms/sample - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0657 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d26f92a90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=15, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 54s 1ms/sample - loss: 0.1551 - accuracy: 0.9549 - val_loss: 0.1393 - val_accuracy: 0.9670\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 53s 1ms/sample - loss: 0.0800 - accuracy: 0.9780 - val_loss: 0.0748 - val_accuracy: 0.9830\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 53s 1ms/sample - loss: 0.0577 - accuracy: 0.9847 - val_loss: 0.0667 - val_accuracy: 0.9795\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 53s 1ms/sample - loss: 0.0529 - accuracy: 0.9857 - val_loss: 0.0950 - val_accuracy: 0.9800\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 52s 1ms/sample - loss: 0.0428 - accuracy: 0.9882 - val_loss: 0.1805 - val_accuracy: 0.9460\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 53s 1ms/sample - loss: 0.0360 - accuracy: 0.9898 - val_loss: 0.0465 - val_accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 54s 1ms/sample - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.0502 - val_accuracy: 0.9865\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 53s 1ms/sample - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.0444 - val_accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 54s 1ms/sample - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0464 - val_accuracy: 0.9895\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 52s 1ms/sample - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.0770 - val_accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d4eca9940>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(x_test.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2150906e-11, 1.4869506e-17, 1.0000000e+00, 1.2496015e-10,\n",
       "       5.3824264e-16, 4.2247170e-15, 8.5330716e-19, 3.3897047e-12,\n",
       "       1.9689440e-16, 8.9077703e-15], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(prediction).to_csv('200130_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d4ff58a90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[49].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2=model2.predict(x_test.astype(float))\n",
    "pd.DataFrame(prediction2).to_csv('200130_submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction3=model3.predict(x_test.astype(float))\n",
    "pd.DataFrame(prediction3).to_csv('200130_submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json=model.to_json()\n",
    "with open(\"200130_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model_json=model2.to_json()\n",
    "with open(\"200130_model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model_json=model3.to_json()\n",
    "with open(\"200130_model3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"200130_model.h5\")\n",
    "model2.save_weights(\"200130_model2.h5\")\n",
    "model3.save_weights(\"200130_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
